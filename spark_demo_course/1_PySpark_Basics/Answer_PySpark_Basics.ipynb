{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "trained-moses",
   "metadata": {},
   "source": [
    "import libraries(I provide all libs that I need when make this tasks, if you need some external import them here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "induced-african",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-25T00:50:38.993348Z",
     "end_time": "2023-04-25T00:50:39.319621Z"
    }
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import max, avg, min\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "from pyspark.sql.functions import when\n",
    "\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "permanent-photographer",
   "metadata": {},
   "source": [
    "create local SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "file_path = 'dataset/ds_salaries.csv'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-25T00:50:39.002550Z",
     "end_time": "2023-04-25T00:50:39.322378Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "stock-partnership",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-25T00:50:39.005730Z",
     "end_time": "2023-04-25T00:50:39.587319Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 796 µs, sys: 449 µs, total: 1.25 ms\n",
      "Wall time: 1.67 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "spark = SparkSession.builder.appName('myApp').master('local[*]').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "juvenile-blame",
   "metadata": {},
   "source": [
    "read csv with inferschema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "computational-liverpool",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-25T00:50:39.015062Z",
     "end_time": "2023-04-25T00:50:39.698435Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.69 ms, sys: 408 µs, total: 2.1 ms\n",
      "Wall time: 115 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = spark.read.options(header=True, inferSchema=True).csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stopped-dominant",
   "metadata": {},
   "source": [
    "read csv one more time with the same code and you will see that it almostly don't take time, because info already in SparkSession and it will not read nothing\n",
    "from this file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aging-neighborhood",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-25T00:50:39.136602Z",
     "end_time": "2023-04-25T00:50:39.796069Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.26 ms, sys: 0 ns, total: 3.26 ms\n",
      "Wall time: 148 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_schema = spark.read.options(header=True, inferSchema=True).csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mature-tomorrow",
   "metadata": {},
   "source": [
    "write schema of scv on screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "least-communications",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-25T00:50:39.285953Z",
     "end_time": "2023-04-25T00:50:39.798077Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- work_year: integer (nullable = true)\n",
      " |-- experience_level: string (nullable = true)\n",
      " |-- employment_type: string (nullable = true)\n",
      " |-- job_title: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      " |-- salary_currency: string (nullable = true)\n",
      " |-- salary_in_usd: integer (nullable = true)\n",
      " |-- employee_residence: string (nullable = true)\n",
      " |-- remote_ratio: integer (nullable = true)\n",
      " |-- company_location: string (nullable = true)\n",
      " |-- company_size: string (nullable = true)\n",
      "\n",
      "CPU times: user 0 ns, sys: 944 µs, total: 944 µs\n",
      "Wall time: 705 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_schema.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "connected-brother",
   "metadata": {},
   "source": [
    "create schema of this scv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "progressive-dictionary",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-25T00:50:39.300439Z",
     "end_time": "2023-04-25T00:50:39.798299Z"
    }
   },
   "outputs": [],
   "source": [
    "my_schema = StructType([\n",
    "        StructField('id', IntegerType(), True),\n",
    "        StructField('work_year', IntegerType(), True),\n",
    "        StructField('experience_lev', StringType(), True),\n",
    "        StructField('employee_type', StringType(), True),\n",
    "        StructField('job_title', StringType(), True),\n",
    "        StructField('salary', IntegerType(), True),\n",
    "        StructField('salary_currency', StringType(), True),\n",
    "        StructField('salary_in_usd', IntegerType(), True),\n",
    "        StructField('employee_residence', StringType(), True),\n",
    "        StructField('remote_ratio', IntegerType(), True),\n",
    "        StructField('company_location', StringType(), True),\n",
    "        StructField('company_size', StringType(), True)\n",
    "     ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auburn-sauce",
   "metadata": {},
   "source": [
    "restart kernel without cleaning output and after restarting you need to initialize SparkSession, after initialize start execute only cells from cell with schema=\n",
    "=StructType.... \n",
    "To restart kernel click Kernel, Restart."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artistic-hospital",
   "metadata": {},
   "source": [
    "read ds_salaries with predefined schema and compare results from this cell and cell with inferSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "literary-plaintiff",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-25T00:50:39.300494Z",
     "end_time": "2023-04-25T00:50:39.823238Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.82 ms, sys: 1.01 ms, total: 2.83 ms\n",
      "Wall time: 14.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "new_df = spark.read.options(header=True).schema(my_schema).csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "senior-joint",
   "metadata": {},
   "source": [
    "this happens because read operation is lazy(transformation), but if you use inferschema it start to be action that will create Spark Job, because Spark need to loop throw all file to check datatypes for all columns and this can harm to your code(if we compare to parquet, it will also go to check data types, but parquet provide meta information, so Spark will not go throw all file, he will just read meta information, but csv don't provide such meta information). Also header make Spark to create one more Spark Job to check first line\n",
    "to define name of columns and remember to skeep it when reading. Actual reading start when you will use first action. More about Spark Jobs you will see in next topic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "underlying-assurance",
   "metadata": {},
   "source": [
    "write schema of scv on screen one more time and compare with previous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "solid-infection",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-25T00:50:39.360503Z",
     "end_time": "2023-04-25T00:50:39.823590Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- work_year: integer (nullable = true)\n",
      " |-- experience_lev: string (nullable = true)\n",
      " |-- employee_type: string (nullable = true)\n",
      " |-- job_title: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      " |-- salary_currency: string (nullable = true)\n",
      " |-- salary_in_usd: integer (nullable = true)\n",
      " |-- employee_residence: string (nullable = true)\n",
      " |-- remote_ratio: integer (nullable = true)\n",
      " |-- company_location: string (nullable = true)\n",
      " |-- company_size: string (nullable = true)\n",
      "\n",
      "CPU times: user 1.18 ms, sys: 659 µs, total: 1.84 ms\n",
      "Wall time: 1.86 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "new_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "close-water",
   "metadata": {},
   "source": [
    "now continue to work with one of the dataframes that you create"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "piano-belgium",
   "metadata": {},
   "source": [
    "print data in dataframe using df.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "legendary-alarm",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-25T00:50:39.360582Z",
     "end_time": "2023-04-25T00:50:39.824583Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+----------------+---------------+--------------------+--------+---------------+-------------+------------------+------------+----------------+------------+\n",
      "| id|work_year|experience_level|employment_type|           job_title|  salary|salary_currency|salary_in_usd|employee_residence|remote_ratio|company_location|company_size|\n",
      "+---+---------+----------------+---------------+--------------------+--------+---------------+-------------+------------------+------------+----------------+------------+\n",
      "|  0|     2020|              MI|             FT|      Data Scientist|   70000|            EUR|        79833|                DE|           0|              DE|           L|\n",
      "|  1|     2020|              SE|             FT|Machine Learning ...|  260000|            USD|       260000|                JP|           0|              JP|           S|\n",
      "|  2|     2020|              SE|             FT|   Big Data Engineer|   85000|            GBP|       109024|                GB|          50|              GB|           M|\n",
      "|  3|     2020|              MI|             FT|Product Data Analyst|   20000|            USD|        20000|                HN|           0|              HN|           S|\n",
      "|  4|     2020|              SE|             FT|Machine Learning ...|  150000|            USD|       150000|                US|          50|              US|           L|\n",
      "|  5|     2020|              EN|             FT|        Data Analyst|   72000|            USD|        72000|                US|         100|              US|           L|\n",
      "|  6|     2020|              SE|             FT| Lead Data Scientist|  190000|            USD|       190000|                US|         100|              US|           S|\n",
      "|  7|     2020|              MI|             FT|      Data Scientist|11000000|            HUF|        35735|                HU|          50|              HU|           L|\n",
      "|  8|     2020|              MI|             FT|Business Data Ana...|  135000|            USD|       135000|                US|         100|              US|           L|\n",
      "|  9|     2020|              SE|             FT|  Lead Data Engineer|  125000|            USD|       125000|                NZ|          50|              NZ|           S|\n",
      "| 10|     2020|              EN|             FT|      Data Scientist|   45000|            EUR|        51321|                FR|           0|              FR|           S|\n",
      "| 11|     2020|              MI|             FT|      Data Scientist| 3000000|            INR|        40481|                IN|           0|              IN|           L|\n",
      "| 12|     2020|              EN|             FT|      Data Scientist|   35000|            EUR|        39916|                FR|           0|              FR|           M|\n",
      "| 13|     2020|              MI|             FT|   Lead Data Analyst|   87000|            USD|        87000|                US|         100|              US|           L|\n",
      "| 14|     2020|              MI|             FT|        Data Analyst|   85000|            USD|        85000|                US|         100|              US|           L|\n",
      "| 15|     2020|              MI|             FT|        Data Analyst|    8000|            USD|         8000|                PK|          50|              PK|           L|\n",
      "| 16|     2020|              EN|             FT|       Data Engineer| 4450000|            JPY|        41689|                JP|         100|              JP|           S|\n",
      "| 17|     2020|              SE|             FT|   Big Data Engineer|  100000|            EUR|       114047|                PL|         100|              GB|           S|\n",
      "| 18|     2020|              EN|             FT|Data Science Cons...|  423000|            INR|         5707|                IN|          50|              IN|           M|\n",
      "| 19|     2020|              MI|             FT|  Lead Data Engineer|   56000|            USD|        56000|                PT|         100|              US|           M|\n",
      "+---+---------+----------------+---------------+--------------------+--------+---------------+-------------+------------------+------------+----------------+------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "CPU times: user 2.68 ms, sys: 0 ns, total: 2.68 ms\n",
      "Wall time: 70.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/04/25 00:50:39 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , work_year, experience_level, employment_type, job_title, salary, salary_currency, salary_in_usd, employee_residence, remote_ratio, company_location, company_size\n",
      " Schema: _c0, work_year, experience_level, employment_type, job_title, salary, salary_currency, salary_in_usd, employee_residence, remote_ratio, company_location, company_size\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/tonipaltus/Innowise/spark_demo/spark_demo_course/1_PySpark_Basics/dataset/ds_salaries.csv\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = df.withColumnRenamed('_c0', 'id')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tamil-medium",
   "metadata": {},
   "source": [
    "print data in dataframe using display(df.toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "connected-dryer",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-25T00:50:39.403196Z",
     "end_time": "2023-04-25T00:50:39.825207Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/04/25 00:50:39 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , work_year, experience_level, employment_type, job_title, salary, salary_currency, salary_in_usd, employee_residence, remote_ratio, company_location, company_size\n",
      " Schema: _c0, work_year, experience_level, employment_type, job_title, salary, salary_currency, salary_in_usd, employee_residence, remote_ratio, company_location, company_size\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/tonipaltus/Innowise/spark_demo/spark_demo_course/1_PySpark_Basics/dataset/ds_salaries.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": "      id  work_year experience_level employment_type   \n0      0       2020               MI              FT  \\\n1      1       2020               SE              FT   \n2      2       2020               SE              FT   \n3      3       2020               MI              FT   \n4      4       2020               SE              FT   \n..   ...        ...              ...             ...   \n602  602       2022               SE              FT   \n603  603       2022               SE              FT   \n604  604       2022               SE              FT   \n605  605       2022               SE              FT   \n606  606       2022               MI              FT   \n\n                      job_title  salary salary_currency  salary_in_usd   \n0                Data Scientist   70000             EUR          79833  \\\n1    Machine Learning Scientist  260000             USD         260000   \n2             Big Data Engineer   85000             GBP         109024   \n3          Product Data Analyst   20000             USD          20000   \n4     Machine Learning Engineer  150000             USD         150000   \n..                          ...     ...             ...            ...   \n602               Data Engineer  154000             USD         154000   \n603               Data Engineer  126000             USD         126000   \n604                Data Analyst  129000             USD         129000   \n605                Data Analyst  150000             USD         150000   \n606                AI Scientist  200000             USD         200000   \n\n    employee_residence  remote_ratio company_location company_size  \n0                   DE             0               DE            L  \n1                   JP             0               JP            S  \n2                   GB            50               GB            M  \n3                   HN             0               HN            S  \n4                   US            50               US            L  \n..                 ...           ...              ...          ...  \n602                 US           100               US            M  \n603                 US           100               US            M  \n604                 US             0               US            M  \n605                 US           100               US            M  \n606                 IN           100               US            L  \n\n[607 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>work_year</th>\n      <th>experience_level</th>\n      <th>employment_type</th>\n      <th>job_title</th>\n      <th>salary</th>\n      <th>salary_currency</th>\n      <th>salary_in_usd</th>\n      <th>employee_residence</th>\n      <th>remote_ratio</th>\n      <th>company_location</th>\n      <th>company_size</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2020</td>\n      <td>MI</td>\n      <td>FT</td>\n      <td>Data Scientist</td>\n      <td>70000</td>\n      <td>EUR</td>\n      <td>79833</td>\n      <td>DE</td>\n      <td>0</td>\n      <td>DE</td>\n      <td>L</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2020</td>\n      <td>SE</td>\n      <td>FT</td>\n      <td>Machine Learning Scientist</td>\n      <td>260000</td>\n      <td>USD</td>\n      <td>260000</td>\n      <td>JP</td>\n      <td>0</td>\n      <td>JP</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2020</td>\n      <td>SE</td>\n      <td>FT</td>\n      <td>Big Data Engineer</td>\n      <td>85000</td>\n      <td>GBP</td>\n      <td>109024</td>\n      <td>GB</td>\n      <td>50</td>\n      <td>GB</td>\n      <td>M</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>2020</td>\n      <td>MI</td>\n      <td>FT</td>\n      <td>Product Data Analyst</td>\n      <td>20000</td>\n      <td>USD</td>\n      <td>20000</td>\n      <td>HN</td>\n      <td>0</td>\n      <td>HN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>2020</td>\n      <td>SE</td>\n      <td>FT</td>\n      <td>Machine Learning Engineer</td>\n      <td>150000</td>\n      <td>USD</td>\n      <td>150000</td>\n      <td>US</td>\n      <td>50</td>\n      <td>US</td>\n      <td>L</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>602</th>\n      <td>602</td>\n      <td>2022</td>\n      <td>SE</td>\n      <td>FT</td>\n      <td>Data Engineer</td>\n      <td>154000</td>\n      <td>USD</td>\n      <td>154000</td>\n      <td>US</td>\n      <td>100</td>\n      <td>US</td>\n      <td>M</td>\n    </tr>\n    <tr>\n      <th>603</th>\n      <td>603</td>\n      <td>2022</td>\n      <td>SE</td>\n      <td>FT</td>\n      <td>Data Engineer</td>\n      <td>126000</td>\n      <td>USD</td>\n      <td>126000</td>\n      <td>US</td>\n      <td>100</td>\n      <td>US</td>\n      <td>M</td>\n    </tr>\n    <tr>\n      <th>604</th>\n      <td>604</td>\n      <td>2022</td>\n      <td>SE</td>\n      <td>FT</td>\n      <td>Data Analyst</td>\n      <td>129000</td>\n      <td>USD</td>\n      <td>129000</td>\n      <td>US</td>\n      <td>0</td>\n      <td>US</td>\n      <td>M</td>\n    </tr>\n    <tr>\n      <th>605</th>\n      <td>605</td>\n      <td>2022</td>\n      <td>SE</td>\n      <td>FT</td>\n      <td>Data Analyst</td>\n      <td>150000</td>\n      <td>USD</td>\n      <td>150000</td>\n      <td>US</td>\n      <td>100</td>\n      <td>US</td>\n      <td>M</td>\n    </tr>\n    <tr>\n      <th>606</th>\n      <td>606</td>\n      <td>2022</td>\n      <td>MI</td>\n      <td>FT</td>\n      <td>AI Scientist</td>\n      <td>200000</td>\n      <td>USD</td>\n      <td>200000</td>\n      <td>IN</td>\n      <td>100</td>\n      <td>US</td>\n      <td>L</td>\n    </tr>\n  </tbody>\n</table>\n<p>607 rows × 12 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27 ms, sys: 1.28 ms, total: 28.2 ms\n",
      "Wall time: 73.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "display(df.toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opponent-gazette",
   "metadata": {},
   "source": [
    "create df_job_title that consists from all job_titles without duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "friendly-cartridge",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-25T00:50:39.482159Z",
     "end_time": "2023-04-25T00:50:39.828167Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.57 ms, sys: 2.12 ms, total: 6.69 ms\n",
      "Wall time: 117 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_job_title = df.select('job_title').dropDuplicates(['job_title']).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offshore-architecture",
   "metadata": {},
   "source": [
    "print all rows from df_job_titles without truncating jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "asian-edition",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-25T00:50:39.612497Z",
     "end_time": "2023-04-25T00:50:39.993042Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 4.53 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                   job_title\n0              3D Computer Vision Researcher\n1                         Lead Data Engineer\n2                   Head of Machine Learning\n3                            Data Specialist\n4                        Data Analytics Lead\n5                 Machine Learning Scientist\n6                          Lead Data Analyst\n7                   Data Engineering Manager\n8                       Staff Data Scientist\n9                              ETL Developer\n10              Director of Data Engineering\n11                      Product Data Analyst\n12                  Principal Data Scientist\n13                              AI Scientist\n14                  Director of Data Science\n15                 Machine Learning Engineer\n16                       Lead Data Scientist\n17  Machine Learning Infrastructure Engineer\n18                     Data Science Engineer\n19                  Machine Learning Manager\n20                        Research Scientist\n21                              Head of Data\n22                       Cloud Data Engineer\n23                Machine Learning Developer\n24                            Data Scientist\n25                      Finance Data Analyst\n26                              Data Analyst\n27                   Data Analytics Engineer\n28                   Data Science Consultant\n29                   Principal Data Engineer\n30            Lead Machine Learning Engineer\n31                               ML Engineer\n32                        Analytics Engineer\n33                      Data Science Manager\n34                     Business Data Analyst\n35                    Principal Data Analyst\n36        Applied Machine Learning Scientist\n37                    Financial Data Analyst\n38                    Data Analytics Manager\n39                  Computer Vision Engineer\n40         Computer Vision Software Engineer\n41                         Big Data Engineer\n42                      Head of Data Science\n43                              NLP Engineer\n44                        Big Data Architect\n45                    Applied Data Scientist\n46                            Data Architect\n47                           BI Data Analyst\n48                    Marketing Data Analyst\n49                             Data Engineer",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>job_title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3D Computer Vision Researcher</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Lead Data Engineer</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Head of Machine Learning</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Data Specialist</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Data Analytics Lead</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Machine Learning Scientist</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Lead Data Analyst</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Data Engineering Manager</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Staff Data Scientist</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>ETL Developer</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Director of Data Engineering</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Product Data Analyst</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Principal Data Scientist</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>AI Scientist</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Director of Data Science</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Machine Learning Engineer</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Lead Data Scientist</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Machine Learning Infrastructure Engineer</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Data Science Engineer</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Machine Learning Manager</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>Research Scientist</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Head of Data</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>Cloud Data Engineer</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>Machine Learning Developer</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>Data Scientist</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>Finance Data Analyst</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>Data Analyst</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>Data Analytics Engineer</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>Data Science Consultant</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>Principal Data Engineer</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>Lead Machine Learning Engineer</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>ML Engineer</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>Analytics Engineer</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>Data Science Manager</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>Business Data Analyst</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>Principal Data Analyst</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>Applied Machine Learning Scientist</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>Financial Data Analyst</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>Data Analytics Manager</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>Computer Vision Engineer</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>Computer Vision Software Engineer</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>Big Data Engineer</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>Head of Data Science</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>NLP Engineer</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>Big Data Architect</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>Applied Data Scientist</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>Data Architect</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>BI Data Analyst</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>Marketing Data Analyst</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>Data Engineer</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df_job_title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interim-pharmacy",
   "metadata": {},
   "source": [
    "create  df_analytic that will consists from max, avg, min USD salaries for all job_titles using groupBy. name of fields is avg_salary, min_salary, max_salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "naval-roller",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-25T00:50:39.660472Z",
     "end_time": "2023-04-25T00:50:39.994097Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.28 ms, sys: 0 ns, total: 5.28 ms\n",
      "Wall time: 21.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_analytic = df.filter(col('salary_currency') == 'USD').groupby('job_title') \\\n",
    "        .agg(\n",
    "        min('salary').alias('min_salary'),\n",
    "        max('salary').alias('max_salary'),\n",
    "        avg('salary').alias('avg_salary')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "french-pledge",
   "metadata": {},
   "source": [
    "print all rows from df_analytic without trancating jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bacterial-depression",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-25T00:50:39.660666Z",
     "end_time": "2023-04-25T00:50:39.994516Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.6 ms, sys: 161 µs, total: 6.77 ms\n",
      "Wall time: 91.9 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                   job_title  min_salary  max_salary   \n0                         Lead Data Engineer       56000      276000  \\\n1                            Data Specialist      165000      165000   \n2                        Data Analytics Lead      405000      405000   \n3                 Machine Learning Scientist       12000      260000   \n4                          Lead Data Analyst       87000      170000   \n5                   Data Engineering Manager      150000      174000   \n6                       Staff Data Scientist      105000      105000   \n7               Director of Data Engineering      200000      200000   \n8                       Product Data Analyst       20000       20000   \n9                   Principal Data Scientist      151000      416000   \n10                              AI Scientist       12000      200000   \n11                  Director of Data Science      168000      325000   \n12                 Machine Learning Engineer       20000      250000   \n13                       Lead Data Scientist      115000      190000   \n14  Machine Learning Infrastructure Engineer      195000      195000   \n15                     Data Science Engineer       60000       60000   \n16                        Research Scientist       42000      450000   \n17                              Head of Data      200000      235000   \n18                       Cloud Data Engineer      160000      160000   \n19                Machine Learning Developer      100000      100000   \n20                            Data Scientist        4000      412000   \n21                              Data Analyst        8000      200000   \n22                   Data Analytics Engineer       20000      110000   \n23                   Data Science Consultant       90000      103000   \n24                   Principal Data Engineer      185000      600000   \n25                               ML Engineer      256000      270000   \n26                        Analytics Engineer      135000      205300   \n27                      Data Science Manager      137141      241000   \n28                     Business Data Analyst      100000      135000   \n29                    Principal Data Analyst       75000      170000   \n30        Applied Machine Learning Scientist       38400      423000   \n31                    Financial Data Analyst      100000      450000   \n32                    Data Analytics Manager      105400      150260   \n33                  Computer Vision Engineer       10000      125000   \n34         Computer Vision Software Engineer       70000      150000   \n35                         Big Data Engineer       18000       70000   \n36                      Head of Data Science       85000      224000   \n37                    Applied Data Scientist      157000      380000   \n38                            Data Architect       90700      266400   \n39                           BI Data Analyst        9272      150000   \n40                             Data Engineer        4000      324000   \n\n       avg_salary  \n0   154250.000000  \n1   165000.000000  \n2   405000.000000  \n3   158412.500000  \n4   128500.000000  \n5   159000.000000  \n6   105000.000000  \n7   200000.000000  \n8    20000.000000  \n9   255500.000000  \n10   79800.000000  \n11  247666.666667  \n12  140488.000000  \n13  152500.000000  \n14  195000.000000  \n15   60000.000000  \n16  139428.428571  \n17  221666.666667  \n18  160000.000000  \n19  100000.000000  \n20  139712.758621  \n21  101761.768293  \n22   60000.000000  \n23   96500.000000  \n24  328333.333333  \n25  263000.000000  \n26  175000.000000  \n27  175118.300000  \n28  117500.000000  \n29  122500.000000  \n30  178800.000000  \n31  275000.000000  \n32  127134.285714  \n33   54750.000000  \n34  110000.000000  \n35   49333.333333  \n36  146718.750000  \n37  238000.000000  \n38  177873.909091  \n39   82454.400000  \n40  139465.800000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>job_title</th>\n      <th>min_salary</th>\n      <th>max_salary</th>\n      <th>avg_salary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Lead Data Engineer</td>\n      <td>56000</td>\n      <td>276000</td>\n      <td>154250.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Data Specialist</td>\n      <td>165000</td>\n      <td>165000</td>\n      <td>165000.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Data Analytics Lead</td>\n      <td>405000</td>\n      <td>405000</td>\n      <td>405000.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Machine Learning Scientist</td>\n      <td>12000</td>\n      <td>260000</td>\n      <td>158412.500000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Lead Data Analyst</td>\n      <td>87000</td>\n      <td>170000</td>\n      <td>128500.000000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Data Engineering Manager</td>\n      <td>150000</td>\n      <td>174000</td>\n      <td>159000.000000</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Staff Data Scientist</td>\n      <td>105000</td>\n      <td>105000</td>\n      <td>105000.000000</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Director of Data Engineering</td>\n      <td>200000</td>\n      <td>200000</td>\n      <td>200000.000000</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Product Data Analyst</td>\n      <td>20000</td>\n      <td>20000</td>\n      <td>20000.000000</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Principal Data Scientist</td>\n      <td>151000</td>\n      <td>416000</td>\n      <td>255500.000000</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>AI Scientist</td>\n      <td>12000</td>\n      <td>200000</td>\n      <td>79800.000000</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Director of Data Science</td>\n      <td>168000</td>\n      <td>325000</td>\n      <td>247666.666667</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Machine Learning Engineer</td>\n      <td>20000</td>\n      <td>250000</td>\n      <td>140488.000000</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Lead Data Scientist</td>\n      <td>115000</td>\n      <td>190000</td>\n      <td>152500.000000</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Machine Learning Infrastructure Engineer</td>\n      <td>195000</td>\n      <td>195000</td>\n      <td>195000.000000</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Data Science Engineer</td>\n      <td>60000</td>\n      <td>60000</td>\n      <td>60000.000000</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Research Scientist</td>\n      <td>42000</td>\n      <td>450000</td>\n      <td>139428.428571</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Head of Data</td>\n      <td>200000</td>\n      <td>235000</td>\n      <td>221666.666667</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Cloud Data Engineer</td>\n      <td>160000</td>\n      <td>160000</td>\n      <td>160000.000000</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Machine Learning Developer</td>\n      <td>100000</td>\n      <td>100000</td>\n      <td>100000.000000</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>Data Scientist</td>\n      <td>4000</td>\n      <td>412000</td>\n      <td>139712.758621</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Data Analyst</td>\n      <td>8000</td>\n      <td>200000</td>\n      <td>101761.768293</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>Data Analytics Engineer</td>\n      <td>20000</td>\n      <td>110000</td>\n      <td>60000.000000</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>Data Science Consultant</td>\n      <td>90000</td>\n      <td>103000</td>\n      <td>96500.000000</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>Principal Data Engineer</td>\n      <td>185000</td>\n      <td>600000</td>\n      <td>328333.333333</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>ML Engineer</td>\n      <td>256000</td>\n      <td>270000</td>\n      <td>263000.000000</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>Analytics Engineer</td>\n      <td>135000</td>\n      <td>205300</td>\n      <td>175000.000000</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>Data Science Manager</td>\n      <td>137141</td>\n      <td>241000</td>\n      <td>175118.300000</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>Business Data Analyst</td>\n      <td>100000</td>\n      <td>135000</td>\n      <td>117500.000000</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>Principal Data Analyst</td>\n      <td>75000</td>\n      <td>170000</td>\n      <td>122500.000000</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>Applied Machine Learning Scientist</td>\n      <td>38400</td>\n      <td>423000</td>\n      <td>178800.000000</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>Financial Data Analyst</td>\n      <td>100000</td>\n      <td>450000</td>\n      <td>275000.000000</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>Data Analytics Manager</td>\n      <td>105400</td>\n      <td>150260</td>\n      <td>127134.285714</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>Computer Vision Engineer</td>\n      <td>10000</td>\n      <td>125000</td>\n      <td>54750.000000</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>Computer Vision Software Engineer</td>\n      <td>70000</td>\n      <td>150000</td>\n      <td>110000.000000</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>Big Data Engineer</td>\n      <td>18000</td>\n      <td>70000</td>\n      <td>49333.333333</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>Head of Data Science</td>\n      <td>85000</td>\n      <td>224000</td>\n      <td>146718.750000</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>Applied Data Scientist</td>\n      <td>157000</td>\n      <td>380000</td>\n      <td>238000.000000</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>Data Architect</td>\n      <td>90700</td>\n      <td>266400</td>\n      <td>177873.909091</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>BI Data Analyst</td>\n      <td>9272</td>\n      <td>150000</td>\n      <td>82454.400000</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>Data Engineer</td>\n      <td>4000</td>\n      <td>324000</td>\n      <td>139465.800000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df_analytic.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hazardous-color",
   "metadata": {},
   "source": [
    "now you need to add in df_analytic column row_id, that will show order of all job_titles depending on avg salary. they should be descending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "nearby-treasurer",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-25T00:50:39.788516Z",
     "end_time": "2023-04-25T00:50:39.994678Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.64 ms, sys: 877 µs, total: 2.52 ms\n",
      "Wall time: 12.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "windowSpec = Window.partitionBy().orderBy(col('avg_salary').desc())\n",
    "df_analytic_sort = df_analytic.withColumn(\"row_id\", row_number().over(windowSpec))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documented-catalog",
   "metadata": {},
   "source": [
    "print all data from df_analytic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "confirmed-monitoring",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-25T00:50:39.788760Z",
     "end_time": "2023-04-25T00:50:40.112013Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.68 ms, sys: 0 ns, total: 8.68 ms\n",
      "Wall time: 157 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/04/25 00:50:39 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/04/25 00:50:39 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/04/25 00:50:39 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/04/25 00:50:39 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/04/25 00:50:39 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/04/25 00:50:39 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/04/25 00:50:39 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                   job_title  min_salary  max_salary   \n0                        Data Analytics Lead      405000      405000  \\\n1                    Principal Data Engineer      185000      600000   \n2                     Financial Data Analyst      100000      450000   \n3                                ML Engineer      256000      270000   \n4                   Principal Data Scientist      151000      416000   \n5                   Director of Data Science      168000      325000   \n6                     Applied Data Scientist      157000      380000   \n7                               Head of Data      200000      235000   \n8               Director of Data Engineering      200000      200000   \n9   Machine Learning Infrastructure Engineer      195000      195000   \n10        Applied Machine Learning Scientist       38400      423000   \n11                            Data Architect       90700      266400   \n12                      Data Science Manager      137141      241000   \n13                        Analytics Engineer      135000      205300   \n14                           Data Specialist      165000      165000   \n15                       Cloud Data Engineer      160000      160000   \n16                  Data Engineering Manager      150000      174000   \n17                Machine Learning Scientist       12000      260000   \n18                        Lead Data Engineer       56000      276000   \n19                       Lead Data Scientist      115000      190000   \n20                      Head of Data Science       85000      224000   \n21                 Machine Learning Engineer       20000      250000   \n22                            Data Scientist        4000      412000   \n23                             Data Engineer        4000      324000   \n24                        Research Scientist       42000      450000   \n25                         Lead Data Analyst       87000      170000   \n26                    Data Analytics Manager      105400      150260   \n27                    Principal Data Analyst       75000      170000   \n28                     Business Data Analyst      100000      135000   \n29         Computer Vision Software Engineer       70000      150000   \n30                      Staff Data Scientist      105000      105000   \n31                              Data Analyst        8000      200000   \n32                Machine Learning Developer      100000      100000   \n33                   Data Science Consultant       90000      103000   \n34                           BI Data Analyst        9272      150000   \n35                              AI Scientist       12000      200000   \n36                     Data Science Engineer       60000       60000   \n37                   Data Analytics Engineer       20000      110000   \n38                  Computer Vision Engineer       10000      125000   \n39                         Big Data Engineer       18000       70000   \n40                      Product Data Analyst       20000       20000   \n\n       avg_salary  row_id  \n0   405000.000000       1  \n1   328333.333333       2  \n2   275000.000000       3  \n3   263000.000000       4  \n4   255500.000000       5  \n5   247666.666667       6  \n6   238000.000000       7  \n7   221666.666667       8  \n8   200000.000000       9  \n9   195000.000000      10  \n10  178800.000000      11  \n11  177873.909091      12  \n12  175118.300000      13  \n13  175000.000000      14  \n14  165000.000000      15  \n15  160000.000000      16  \n16  159000.000000      17  \n17  158412.500000      18  \n18  154250.000000      19  \n19  152500.000000      20  \n20  146718.750000      21  \n21  140488.000000      22  \n22  139712.758621      23  \n23  139465.800000      24  \n24  139428.428571      25  \n25  128500.000000      26  \n26  127134.285714      27  \n27  122500.000000      28  \n28  117500.000000      29  \n29  110000.000000      30  \n30  105000.000000      31  \n31  101761.768293      32  \n32  100000.000000      33  \n33   96500.000000      34  \n34   82454.400000      35  \n35   79800.000000      36  \n36   60000.000000      37  \n37   60000.000000      38  \n38   54750.000000      39  \n39   49333.333333      40  \n40   20000.000000      41  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>job_title</th>\n      <th>min_salary</th>\n      <th>max_salary</th>\n      <th>avg_salary</th>\n      <th>row_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Data Analytics Lead</td>\n      <td>405000</td>\n      <td>405000</td>\n      <td>405000.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Principal Data Engineer</td>\n      <td>185000</td>\n      <td>600000</td>\n      <td>328333.333333</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Financial Data Analyst</td>\n      <td>100000</td>\n      <td>450000</td>\n      <td>275000.000000</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ML Engineer</td>\n      <td>256000</td>\n      <td>270000</td>\n      <td>263000.000000</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Principal Data Scientist</td>\n      <td>151000</td>\n      <td>416000</td>\n      <td>255500.000000</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Director of Data Science</td>\n      <td>168000</td>\n      <td>325000</td>\n      <td>247666.666667</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Applied Data Scientist</td>\n      <td>157000</td>\n      <td>380000</td>\n      <td>238000.000000</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Head of Data</td>\n      <td>200000</td>\n      <td>235000</td>\n      <td>221666.666667</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Director of Data Engineering</td>\n      <td>200000</td>\n      <td>200000</td>\n      <td>200000.000000</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Machine Learning Infrastructure Engineer</td>\n      <td>195000</td>\n      <td>195000</td>\n      <td>195000.000000</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Applied Machine Learning Scientist</td>\n      <td>38400</td>\n      <td>423000</td>\n      <td>178800.000000</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Data Architect</td>\n      <td>90700</td>\n      <td>266400</td>\n      <td>177873.909091</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Data Science Manager</td>\n      <td>137141</td>\n      <td>241000</td>\n      <td>175118.300000</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Analytics Engineer</td>\n      <td>135000</td>\n      <td>205300</td>\n      <td>175000.000000</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Data Specialist</td>\n      <td>165000</td>\n      <td>165000</td>\n      <td>165000.000000</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Cloud Data Engineer</td>\n      <td>160000</td>\n      <td>160000</td>\n      <td>160000.000000</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Data Engineering Manager</td>\n      <td>150000</td>\n      <td>174000</td>\n      <td>159000.000000</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Machine Learning Scientist</td>\n      <td>12000</td>\n      <td>260000</td>\n      <td>158412.500000</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Lead Data Engineer</td>\n      <td>56000</td>\n      <td>276000</td>\n      <td>154250.000000</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Lead Data Scientist</td>\n      <td>115000</td>\n      <td>190000</td>\n      <td>152500.000000</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>Head of Data Science</td>\n      <td>85000</td>\n      <td>224000</td>\n      <td>146718.750000</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Machine Learning Engineer</td>\n      <td>20000</td>\n      <td>250000</td>\n      <td>140488.000000</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>Data Scientist</td>\n      <td>4000</td>\n      <td>412000</td>\n      <td>139712.758621</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>Data Engineer</td>\n      <td>4000</td>\n      <td>324000</td>\n      <td>139465.800000</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>Research Scientist</td>\n      <td>42000</td>\n      <td>450000</td>\n      <td>139428.428571</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>Lead Data Analyst</td>\n      <td>87000</td>\n      <td>170000</td>\n      <td>128500.000000</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>Data Analytics Manager</td>\n      <td>105400</td>\n      <td>150260</td>\n      <td>127134.285714</td>\n      <td>27</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>Principal Data Analyst</td>\n      <td>75000</td>\n      <td>170000</td>\n      <td>122500.000000</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>Business Data Analyst</td>\n      <td>100000</td>\n      <td>135000</td>\n      <td>117500.000000</td>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>Computer Vision Software Engineer</td>\n      <td>70000</td>\n      <td>150000</td>\n      <td>110000.000000</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>Staff Data Scientist</td>\n      <td>105000</td>\n      <td>105000</td>\n      <td>105000.000000</td>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>Data Analyst</td>\n      <td>8000</td>\n      <td>200000</td>\n      <td>101761.768293</td>\n      <td>32</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>Machine Learning Developer</td>\n      <td>100000</td>\n      <td>100000</td>\n      <td>100000.000000</td>\n      <td>33</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>Data Science Consultant</td>\n      <td>90000</td>\n      <td>103000</td>\n      <td>96500.000000</td>\n      <td>34</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>BI Data Analyst</td>\n      <td>9272</td>\n      <td>150000</td>\n      <td>82454.400000</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>AI Scientist</td>\n      <td>12000</td>\n      <td>200000</td>\n      <td>79800.000000</td>\n      <td>36</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>Data Science Engineer</td>\n      <td>60000</td>\n      <td>60000</td>\n      <td>60000.000000</td>\n      <td>37</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>Data Analytics Engineer</td>\n      <td>20000</td>\n      <td>110000</td>\n      <td>60000.000000</td>\n      <td>38</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>Computer Vision Engineer</td>\n      <td>10000</td>\n      <td>125000</td>\n      <td>54750.000000</td>\n      <td>39</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>Big Data Engineer</td>\n      <td>18000</td>\n      <td>70000</td>\n      <td>49333.333333</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>Product Data Analyst</td>\n      <td>20000</td>\n      <td>20000</td>\n      <td>20000.000000</td>\n      <td>41</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df_analytic_sort.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satellite-quarter",
   "metadata": {},
   "source": [
    "it isn't beautifull, so we need to put now row_id on first place in df_analytic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ranging-tribune",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-25T00:50:39.972434Z",
     "end_time": "2023-04-25T00:50:40.112927Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.62 ms, sys: 54 µs, total: 2.67 ms\n",
      "Wall time: 12.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_analytic = df_analytic_sort.select('row_id', 'job_title', 'max_salary', 'avg_salary', 'min_salary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reliable-amsterdam",
   "metadata": {},
   "source": [
    "print df_analytic now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "classical-biology",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-25T00:50:39.972606Z",
     "end_time": "2023-04-25T00:50:40.368662Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/04/25 00:50:39 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/04/25 00:50:39 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/04/25 00:50:39 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.53 ms, sys: 0 ns, total: 7.53 ms\n",
      "Wall time: 184 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/04/25 00:50:40 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/04/25 00:50:40 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/04/25 00:50:40 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/04/25 00:50:40 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "data": {
      "text/plain": "    row_id                                 job_title  max_salary   \n0        1                       Data Analytics Lead      405000  \\\n1        2                   Principal Data Engineer      600000   \n2        3                    Financial Data Analyst      450000   \n3        4                               ML Engineer      270000   \n4        5                  Principal Data Scientist      416000   \n5        6                  Director of Data Science      325000   \n6        7                    Applied Data Scientist      380000   \n7        8                              Head of Data      235000   \n8        9              Director of Data Engineering      200000   \n9       10  Machine Learning Infrastructure Engineer      195000   \n10      11        Applied Machine Learning Scientist      423000   \n11      12                            Data Architect      266400   \n12      13                      Data Science Manager      241000   \n13      14                        Analytics Engineer      205300   \n14      15                           Data Specialist      165000   \n15      16                       Cloud Data Engineer      160000   \n16      17                  Data Engineering Manager      174000   \n17      18                Machine Learning Scientist      260000   \n18      19                        Lead Data Engineer      276000   \n19      20                       Lead Data Scientist      190000   \n20      21                      Head of Data Science      224000   \n21      22                 Machine Learning Engineer      250000   \n22      23                            Data Scientist      412000   \n23      24                             Data Engineer      324000   \n24      25                        Research Scientist      450000   \n25      26                         Lead Data Analyst      170000   \n26      27                    Data Analytics Manager      150260   \n27      28                    Principal Data Analyst      170000   \n28      29                     Business Data Analyst      135000   \n29      30         Computer Vision Software Engineer      150000   \n30      31                      Staff Data Scientist      105000   \n31      32                              Data Analyst      200000   \n32      33                Machine Learning Developer      100000   \n33      34                   Data Science Consultant      103000   \n34      35                           BI Data Analyst      150000   \n35      36                              AI Scientist      200000   \n36      37                     Data Science Engineer       60000   \n37      38                   Data Analytics Engineer      110000   \n38      39                  Computer Vision Engineer      125000   \n39      40                         Big Data Engineer       70000   \n40      41                      Product Data Analyst       20000   \n\n       avg_salary  min_salary  \n0   405000.000000      405000  \n1   328333.333333      185000  \n2   275000.000000      100000  \n3   263000.000000      256000  \n4   255500.000000      151000  \n5   247666.666667      168000  \n6   238000.000000      157000  \n7   221666.666667      200000  \n8   200000.000000      200000  \n9   195000.000000      195000  \n10  178800.000000       38400  \n11  177873.909091       90700  \n12  175118.300000      137141  \n13  175000.000000      135000  \n14  165000.000000      165000  \n15  160000.000000      160000  \n16  159000.000000      150000  \n17  158412.500000       12000  \n18  154250.000000       56000  \n19  152500.000000      115000  \n20  146718.750000       85000  \n21  140488.000000       20000  \n22  139712.758621        4000  \n23  139465.800000        4000  \n24  139428.428571       42000  \n25  128500.000000       87000  \n26  127134.285714      105400  \n27  122500.000000       75000  \n28  117500.000000      100000  \n29  110000.000000       70000  \n30  105000.000000      105000  \n31  101761.768293        8000  \n32  100000.000000      100000  \n33   96500.000000       90000  \n34   82454.400000        9272  \n35   79800.000000       12000  \n36   60000.000000       60000  \n37   60000.000000       20000  \n38   54750.000000       10000  \n39   49333.333333       18000  \n40   20000.000000       20000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>row_id</th>\n      <th>job_title</th>\n      <th>max_salary</th>\n      <th>avg_salary</th>\n      <th>min_salary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Data Analytics Lead</td>\n      <td>405000</td>\n      <td>405000.000000</td>\n      <td>405000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Principal Data Engineer</td>\n      <td>600000</td>\n      <td>328333.333333</td>\n      <td>185000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Financial Data Analyst</td>\n      <td>450000</td>\n      <td>275000.000000</td>\n      <td>100000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>ML Engineer</td>\n      <td>270000</td>\n      <td>263000.000000</td>\n      <td>256000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Principal Data Scientist</td>\n      <td>416000</td>\n      <td>255500.000000</td>\n      <td>151000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>Director of Data Science</td>\n      <td>325000</td>\n      <td>247666.666667</td>\n      <td>168000</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>Applied Data Scientist</td>\n      <td>380000</td>\n      <td>238000.000000</td>\n      <td>157000</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>Head of Data</td>\n      <td>235000</td>\n      <td>221666.666667</td>\n      <td>200000</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>Director of Data Engineering</td>\n      <td>200000</td>\n      <td>200000.000000</td>\n      <td>200000</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>Machine Learning Infrastructure Engineer</td>\n      <td>195000</td>\n      <td>195000.000000</td>\n      <td>195000</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>11</td>\n      <td>Applied Machine Learning Scientist</td>\n      <td>423000</td>\n      <td>178800.000000</td>\n      <td>38400</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>12</td>\n      <td>Data Architect</td>\n      <td>266400</td>\n      <td>177873.909091</td>\n      <td>90700</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>13</td>\n      <td>Data Science Manager</td>\n      <td>241000</td>\n      <td>175118.300000</td>\n      <td>137141</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>14</td>\n      <td>Analytics Engineer</td>\n      <td>205300</td>\n      <td>175000.000000</td>\n      <td>135000</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>15</td>\n      <td>Data Specialist</td>\n      <td>165000</td>\n      <td>165000.000000</td>\n      <td>165000</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>16</td>\n      <td>Cloud Data Engineer</td>\n      <td>160000</td>\n      <td>160000.000000</td>\n      <td>160000</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>17</td>\n      <td>Data Engineering Manager</td>\n      <td>174000</td>\n      <td>159000.000000</td>\n      <td>150000</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>18</td>\n      <td>Machine Learning Scientist</td>\n      <td>260000</td>\n      <td>158412.500000</td>\n      <td>12000</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>19</td>\n      <td>Lead Data Engineer</td>\n      <td>276000</td>\n      <td>154250.000000</td>\n      <td>56000</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>20</td>\n      <td>Lead Data Scientist</td>\n      <td>190000</td>\n      <td>152500.000000</td>\n      <td>115000</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>21</td>\n      <td>Head of Data Science</td>\n      <td>224000</td>\n      <td>146718.750000</td>\n      <td>85000</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>22</td>\n      <td>Machine Learning Engineer</td>\n      <td>250000</td>\n      <td>140488.000000</td>\n      <td>20000</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>23</td>\n      <td>Data Scientist</td>\n      <td>412000</td>\n      <td>139712.758621</td>\n      <td>4000</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>24</td>\n      <td>Data Engineer</td>\n      <td>324000</td>\n      <td>139465.800000</td>\n      <td>4000</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>25</td>\n      <td>Research Scientist</td>\n      <td>450000</td>\n      <td>139428.428571</td>\n      <td>42000</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>26</td>\n      <td>Lead Data Analyst</td>\n      <td>170000</td>\n      <td>128500.000000</td>\n      <td>87000</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>27</td>\n      <td>Data Analytics Manager</td>\n      <td>150260</td>\n      <td>127134.285714</td>\n      <td>105400</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>28</td>\n      <td>Principal Data Analyst</td>\n      <td>170000</td>\n      <td>122500.000000</td>\n      <td>75000</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>29</td>\n      <td>Business Data Analyst</td>\n      <td>135000</td>\n      <td>117500.000000</td>\n      <td>100000</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>30</td>\n      <td>Computer Vision Software Engineer</td>\n      <td>150000</td>\n      <td>110000.000000</td>\n      <td>70000</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>31</td>\n      <td>Staff Data Scientist</td>\n      <td>105000</td>\n      <td>105000.000000</td>\n      <td>105000</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>32</td>\n      <td>Data Analyst</td>\n      <td>200000</td>\n      <td>101761.768293</td>\n      <td>8000</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>33</td>\n      <td>Machine Learning Developer</td>\n      <td>100000</td>\n      <td>100000.000000</td>\n      <td>100000</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>34</td>\n      <td>Data Science Consultant</td>\n      <td>103000</td>\n      <td>96500.000000</td>\n      <td>90000</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>35</td>\n      <td>BI Data Analyst</td>\n      <td>150000</td>\n      <td>82454.400000</td>\n      <td>9272</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>36</td>\n      <td>AI Scientist</td>\n      <td>200000</td>\n      <td>79800.000000</td>\n      <td>12000</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>37</td>\n      <td>Data Science Engineer</td>\n      <td>60000</td>\n      <td>60000.000000</td>\n      <td>60000</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>38</td>\n      <td>Data Analytics Engineer</td>\n      <td>110000</td>\n      <td>60000.000000</td>\n      <td>20000</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>39</td>\n      <td>Computer Vision Engineer</td>\n      <td>125000</td>\n      <td>54750.000000</td>\n      <td>10000</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>40</td>\n      <td>Big Data Engineer</td>\n      <td>70000</td>\n      <td>49333.333333</td>\n      <td>18000</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>41</td>\n      <td>Product Data Analyst</td>\n      <td>20000</td>\n      <td>20000.000000</td>\n      <td>20000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df_analytic.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hybrid-queensland",
   "metadata": {},
   "source": [
    "here you need to create df_exp_lvl with the biggest usd_salary(biggest_salary) for each experience_level(you need to save all fields like in entire dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------------+\n",
      "|experience_level|max(salary_in_usd)|\n",
      "+----------------+------------------+\n",
      "|              EX|            600000|\n",
      "|              MI|            450000|\n",
      "|              EN|            250000|\n",
      "|              SE|            412000|\n",
      "+----------------+------------------+\n",
      "\n",
      "CPU times: user 4.23 ms, sys: 59 µs, total: 4.29 ms\n",
      "Wall time: 89.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "group_data = df.groupBy('experience_level').max('salary_in_usd').show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-25T00:50:40.188842Z",
     "end_time": "2023-04-25T00:50:40.423663Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.82 ms, sys: 57 µs, total: 2.88 ms\n",
      "Wall time: 5.69 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Не знаю как сделать красивее\n",
    "df_exp_lvl = df.filter(\n",
    "        (df['experience_level'] == 'EX') & (df['salary_in_usd'] == 600000) |\n",
    "        (df['experience_level'] == 'MI') & (df['salary_in_usd'] == 450000) |\n",
    "        (df['experience_level'] == 'EN') & (df['salary_in_usd'] == 250000) |\n",
    "        (df['experience_level'] == 'SE') & (df['salary_in_usd'] == 412000)\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-25T00:50:40.236155Z",
     "end_time": "2023-04-25T00:50:40.458363Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "innovative-hierarchy",
   "metadata": {},
   "source": [
    "print here df_exp_lvl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+----------------+---------------+-------------------------+------+---------------+-------------+------------------+------------+----------------+------------+\n",
      "|id |work_year|experience_level|employment_type|job_title                |salary|salary_currency|salary_in_usd|employee_residence|remote_ratio|company_location|company_size|\n",
      "+---+---------+----------------+---------------+-------------------------+------+---------------+-------------+------------------+------------+----------------+------------+\n",
      "|33 |2020     |MI              |FT             |Research Scientist       |450000|USD            |450000       |US                |0           |US              |M           |\n",
      "|37 |2020     |EN              |FT             |Machine Learning Engineer|250000|USD            |250000       |US                |50          |US              |L           |\n",
      "|63 |2020     |SE              |FT             |Data Scientist           |412000|USD            |412000       |US                |100         |US              |L           |\n",
      "|97 |2021     |MI              |FT             |Financial Data Analyst   |450000|USD            |450000       |US                |100         |US              |L           |\n",
      "|252|2021     |EX              |FT             |Principal Data Engineer  |600000|USD            |600000       |US                |100         |US              |L           |\n",
      "+---+---------+----------------+---------------+-------------------------+------+---------------+-------------+------------------+------------+----------------+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/04/25 00:50:40 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , work_year, experience_level, employment_type, job_title, salary, salary_currency, salary_in_usd, employee_residence, remote_ratio, company_location, company_size\n",
      " Schema: _c0, work_year, experience_level, employment_type, job_title, salary, salary_currency, salary_in_usd, employee_residence, remote_ratio, company_location, company_size\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/tonipaltus/Innowise/spark_demo/spark_demo_course/1_PySpark_Basics/dataset/ds_salaries.csv\n"
     ]
    }
   ],
   "source": [
    "df_exp_lvl.show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-25T00:50:40.248487Z",
     "end_time": "2023-04-25T00:50:40.460977Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Или можно так"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "windowSpec = Window.partitionBy('experience_level').orderBy(col('salary_in_usd').desc())\n",
    "df_exp_lvl = df.withColumn('salary_order', row_number().over(windowSpec)).filter(col('salary_order') == 1).drop('salary_order')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-25T00:50:40.303621Z",
     "end_time": "2023-04-25T00:50:40.461641Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/04/25 00:50:40 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , work_year, experience_level, employment_type, job_title, salary, salary_currency, salary_in_usd, employee_residence, remote_ratio, company_location, company_size\n",
      " Schema: _c0, work_year, experience_level, employment_type, job_title, salary, salary_currency, salary_in_usd, employee_residence, remote_ratio, company_location, company_size\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/tonipaltus/Innowise/spark_demo/spark_demo_course/1_PySpark_Basics/dataset/ds_salaries.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": "    id  work_year experience_level employment_type                  job_title   \n0   37       2020               EN              FT  Machine Learning Engineer  \\\n1  252       2021               EX              FT    Principal Data Engineer   \n2   33       2020               MI              FT         Research Scientist   \n3   63       2020               SE              FT             Data Scientist   \n\n   salary salary_currency  salary_in_usd employee_residence  remote_ratio   \n0  250000             USD         250000                 US            50  \\\n1  600000             USD         600000                 US           100   \n2  450000             USD         450000                 US             0   \n3  412000             USD         412000                 US           100   \n\n  company_location company_size  \n0               US            L  \n1               US            L  \n2               US            M  \n3               US            L  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>work_year</th>\n      <th>experience_level</th>\n      <th>employment_type</th>\n      <th>job_title</th>\n      <th>salary</th>\n      <th>salary_currency</th>\n      <th>salary_in_usd</th>\n      <th>employee_residence</th>\n      <th>remote_ratio</th>\n      <th>company_location</th>\n      <th>company_size</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>37</td>\n      <td>2020</td>\n      <td>EN</td>\n      <td>FT</td>\n      <td>Machine Learning Engineer</td>\n      <td>250000</td>\n      <td>USD</td>\n      <td>250000</td>\n      <td>US</td>\n      <td>50</td>\n      <td>US</td>\n      <td>L</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>252</td>\n      <td>2021</td>\n      <td>EX</td>\n      <td>FT</td>\n      <td>Principal Data Engineer</td>\n      <td>600000</td>\n      <td>USD</td>\n      <td>600000</td>\n      <td>US</td>\n      <td>100</td>\n      <td>US</td>\n      <td>L</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>33</td>\n      <td>2020</td>\n      <td>MI</td>\n      <td>FT</td>\n      <td>Research Scientist</td>\n      <td>450000</td>\n      <td>USD</td>\n      <td>450000</td>\n      <td>US</td>\n      <td>0</td>\n      <td>US</td>\n      <td>M</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>63</td>\n      <td>2020</td>\n      <td>SE</td>\n      <td>FT</td>\n      <td>Data Scientist</td>\n      <td>412000</td>\n      <td>USD</td>\n      <td>412000</td>\n      <td>US</td>\n      <td>100</td>\n      <td>US</td>\n      <td>L</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exp_lvl.toPandas()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-25T00:50:40.331245Z",
     "end_time": "2023-04-25T00:50:40.641863Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "hawaiian-mortgage",
   "metadata": {},
   "source": [
    "create df_best that consists from rows where salary of guy same as biggest salary for other people in his exp_lvl and choose only columns: id, experience_level, biggest_salary, employee_residence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "toxic-prompt",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-25T00:50:40.481715Z",
     "end_time": "2023-04-25T00:50:40.673280Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.79 ms, sys: 0 ns, total: 5.79 ms\n",
      "Wall time: 30.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "windowSpec = Window.partitionBy('experience_level').orderBy(col('salary').desc())\n",
    "df_best = df.withColumn('salary_order', row_number().over(windowSpec)).filter(col('salary_order') == 1).drop('salary_order').select('id', 'experience_level', 'salary', 'employee_residence')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complex-librarian",
   "metadata": {},
   "source": [
    "print df_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "smart-texas",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-25T00:50:40.518654Z",
     "end_time": "2023-04-25T00:50:40.693737Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/04/25 00:50:40 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , experience_level, salary, employee_residence\n",
      " Schema: _c0, experience_level, salary, employee_residence\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/tonipaltus/Innowise/spark_demo/spark_demo_course/1_PySpark_Basics/dataset/ds_salaries.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.45 ms, sys: 0 ns, total: 6.45 ms\n",
      "Wall time: 83.1 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": "    id experience_level    salary employee_residence\n0   16               EN   4450000                 JP\n1  384               EX   6000000                 IN\n2  177               MI  30400000                 CL\n3  285               SE   7000000                 IN",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>experience_level</th>\n      <th>salary</th>\n      <th>employee_residence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>16</td>\n      <td>EN</td>\n      <td>4450000</td>\n      <td>JP</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>384</td>\n      <td>EX</td>\n      <td>6000000</td>\n      <td>IN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>177</td>\n      <td>MI</td>\n      <td>30400000</td>\n      <td>CL</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>285</td>\n      <td>SE</td>\n      <td>7000000</td>\n      <td>IN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df_best.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integral-brass",
   "metadata": {},
   "source": [
    "drop duplicates if exist by experience_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "immune-marine",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-25T00:50:40.608000Z",
     "end_time": "2023-04-25T00:50:40.697097Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.32 ms, sys: 357 µs, total: 1.67 ms\n",
      "Wall time: 2.87 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_best = df_best.dropDuplicates(['experience_level'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "connected-credit",
   "metadata": {},
   "source": [
    "print df_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "specified-wellington",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-25T00:50:40.614917Z",
     "end_time": "2023-04-25T00:50:40.980823Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.68 ms, sys: 1.05 ms, total: 7.73 ms\n",
      "Wall time: 124 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/04/25 00:50:40 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , experience_level, salary, employee_residence\n",
      " Schema: _c0, experience_level, salary, employee_residence\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/tonipaltus/Innowise/spark_demo/spark_demo_course/1_PySpark_Basics/dataset/ds_salaries.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": "    id experience_level    salary employee_residence\n0   16               EN   4450000                 JP\n1  384               EX   6000000                 IN\n2  177               MI  30400000                 CL\n3  285               SE   7000000                 IN",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>experience_level</th>\n      <th>salary</th>\n      <th>employee_residence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>16</td>\n      <td>EN</td>\n      <td>4450000</td>\n      <td>JP</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>384</td>\n      <td>EX</td>\n      <td>6000000</td>\n      <td>IN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>177</td>\n      <td>MI</td>\n      <td>30400000</td>\n      <td>CL</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>285</td>\n      <td>SE</td>\n      <td>7000000</td>\n      <td>IN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df_best.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facial-plant",
   "metadata": {},
   "source": [
    "create df_new_best from df_best without id, and make the next: when exp_level = MI we want middle, when SE we want senior, else Null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "infinite-retail",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-25T00:52:45.007398Z",
     "end_time": "2023-04-25T00:52:45.018203Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.6 ms, sys: 779 µs, total: 2.38 ms\n",
      "Wall time: 7.12 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_new_best = df_best.withColumn('degree',\n",
    "                                 when(df.experience_level == 'MI', 'middle').\n",
    "                                 when(df.experience_level == 'SE', 'senior')\n",
    "                                 ).drop('id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changing-fairy",
   "metadata": {},
   "source": [
    "print df_new_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "endless-framework",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-25T00:52:46.968842Z",
     "end_time": "2023-04-25T00:52:47.119260Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.4 ms, sys: 0 ns, total: 7.4 ms\n",
      "Wall time: 130 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": "  experience_level    salary employee_residence  degree\n0               EN   4450000                 JP    None\n1               EX   6000000                 IN    None\n2               MI  30400000                 CL  middle\n3               SE   7000000                 IN  senior",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>experience_level</th>\n      <th>salary</th>\n      <th>employee_residence</th>\n      <th>degree</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>EN</td>\n      <td>4450000</td>\n      <td>JP</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>EX</td>\n      <td>6000000</td>\n      <td>IN</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>MI</td>\n      <td>30400000</td>\n      <td>CL</td>\n      <td>middle</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>SE</td>\n      <td>7000000</td>\n      <td>IN</td>\n      <td>senior</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df_new_best.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mineral-status",
   "metadata": {},
   "source": [
    "write df_new_best like 1.csv and load then it to df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "baking-progress",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-25T00:53:02.278367Z",
     "end_time": "2023-04-25T00:53:02.491816Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.69 ms, sys: 235 µs, total: 4.93 ms\n",
      "Wall time: 214 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_new_best.write.options(header=True).format('csv').mode('overwrite').save('dataset/1.csv')\n",
    "df_final = spark.read.options(header=True).format('csv').load('dataset/1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocal-shooting",
   "metadata": {},
   "source": [
    "print df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "expired-viewer",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-25T00:53:06.866588Z",
     "end_time": "2023-04-25T00:53:07.046959Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.9 ms, sys: 0 ns, total: 11.9 ms\n",
      "Wall time: 138 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": "  experience_level    salary employee_residence  degree\n0               EN   4450000                 JP    None\n1               EX   6000000                 IN    None\n2               MI  30400000                 CL  middle\n3               SE   7000000                 IN  senior",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>experience_level</th>\n      <th>salary</th>\n      <th>employee_residence</th>\n      <th>degree</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>EN</td>\n      <td>4450000</td>\n      <td>JP</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>EX</td>\n      <td>6000000</td>\n      <td>IN</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>MI</td>\n      <td>30400000</td>\n      <td>CL</td>\n      <td>middle</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>SE</td>\n      <td>7000000</td>\n      <td>IN</td>\n      <td>senior</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df_final.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nutritional-progress",
   "metadata": {},
   "source": [
    "filter df_final to delete experience_level where it Null, then join this table by biggest_salary(salary_in_usd) and employee_residence with entire df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "small-polymer",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-25T00:53:43.887366Z",
     "end_time": "2023-04-25T00:53:43.966052Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.67 ms, sys: 4.25 ms, total: 9.92 ms\n",
      "Wall time: 53.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_final = df_final.dropna().join(df, ['salary', 'experience_level'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "variable-twins",
   "metadata": {},
   "source": [
    "print df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/04/25 00:53:45 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , work_year, experience_level, employment_type, job_title, salary, salary_currency, salary_in_usd, employee_residence, remote_ratio, company_location, company_size\n",
      " Schema: _c0, work_year, experience_level, employment_type, job_title, salary, salary_currency, salary_in_usd, employee_residence, remote_ratio, company_location, company_size\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/tonipaltus/Innowise/spark_demo/spark_demo_course/1_PySpark_Basics/dataset/ds_salaries.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": "     salary experience_level employee_residence  degree   id  work_year   \n0  30400000               MI                 CL  middle  177       2021  \\\n1   7000000               SE                 IN  senior  285       2021   \n\n  employment_type             job_title salary_currency  salary_in_usd   \n0              FT        Data Scientist             CLP          40038  \\\n1              FT  Data Science Manager             INR          94665   \n\n  employee_residence  remote_ratio company_location company_size  \n0                 CL           100               CL            L  \n1                 IN            50               IN            L  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>salary</th>\n      <th>experience_level</th>\n      <th>employee_residence</th>\n      <th>degree</th>\n      <th>id</th>\n      <th>work_year</th>\n      <th>employment_type</th>\n      <th>job_title</th>\n      <th>salary_currency</th>\n      <th>salary_in_usd</th>\n      <th>employee_residence</th>\n      <th>remote_ratio</th>\n      <th>company_location</th>\n      <th>company_size</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>30400000</td>\n      <td>MI</td>\n      <td>CL</td>\n      <td>middle</td>\n      <td>177</td>\n      <td>2021</td>\n      <td>FT</td>\n      <td>Data Scientist</td>\n      <td>CLP</td>\n      <td>40038</td>\n      <td>CL</td>\n      <td>100</td>\n      <td>CL</td>\n      <td>L</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7000000</td>\n      <td>SE</td>\n      <td>IN</td>\n      <td>senior</td>\n      <td>285</td>\n      <td>2021</td>\n      <td>FT</td>\n      <td>Data Science Manager</td>\n      <td>INR</td>\n      <td>94665</td>\n      <td>IN</td>\n      <td>50</td>\n      <td>IN</td>\n      <td>L</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.toPandas()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-25T00:53:45.586627Z",
     "end_time": "2023-04-25T00:53:45.780164Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "variable-moore",
   "metadata": {},
   "source": [
    "last task is to save in variable and then print this variable of the biggest salary_in_usd from df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "individual-institution",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-25T00:54:13.252662Z",
     "end_time": "2023-04-25T00:54:13.434853Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94665\n",
      "CPU times: user 10.2 ms, sys: 52 µs, total: 10.3 ms\n",
      "Wall time: 184 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "biggest_salary = df_final.agg(max('salary_in_usd')).collect()[0][0]\n",
    "print(biggest_salary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stopped-procedure",
   "metadata": {},
   "source": [
    "It is the end of PySpark basics. In other lessons you will learn optimizations technics and how to make distributed system"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
